{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import time\n",
        "\n",
        "df = pd.read_csv(\"week11.csv\")\n",
        "\n",
        "# Separate features and target\n",
        "X = df.iloc[:, :-1]\n",
        "y = df.iloc[:, -1]\n",
        "\n",
        "# Preprocess data - standardize features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Define configurations to test\n",
        "configurations = [\n",
        "    {\"data_size\": 1000, \"hidden_layers\": (4,), \"name\": \"1 hidden layer 4 nodes\"},\n",
        "    {\"data_size\": 10000, \"hidden_layers\": (4,), \"name\": \"1 hidden layer 4 nodes\"},\n",
        "    {\"data_size\": 100000, \"hidden_layers\": (4,), \"name\": \"1 hidden layer 4 nodes\"},\n",
        "    {\"data_size\": 1000, \"hidden_layers\": (4, 4), \"name\": \"2 hidden layers of 4 nodes each\"},\n",
        "    {\"data_size\": 10000, \"hidden_layers\": (4, 4), \"name\": \"2 hidden layers of 4 nodes each\"},\n",
        "    {\"data_size\": 100000, \"hidden_layers\": (4, 4), \"name\": \"2 hidden layers of 4 nodes each\"},\n",
        "]\n",
        "\n",
        "# Print header\n",
        "print(f\"{'Data size':<10} {'Configuration':<30} {'Training error':<15} {'Validation error':<15} {'Time (s)':<15}\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "# Test each configuration\n",
        "for config in configurations:\n",
        "    data_size = min(config[\"data_size\"], len(X_scaled))\n",
        "\n",
        "    # Take a subset of data if needed\n",
        "    if data_size < len(X_scaled):\n",
        "        X_sample, _, y_sample, _ = train_test_split(\n",
        "            X_scaled, y, train_size=data_size, random_state=42)\n",
        "    else:\n",
        "        X_sample, y_sample = X_scaled, y\n",
        "\n",
        "    # Split into training and validation sets\n",
        "    X_train, X_val, y_train, y_val = train_test_split(\n",
        "        X_sample, y_sample, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Train model and time execution\n",
        "    start_time = time.time()\n",
        "\n",
        "    model = MLPClassifier(\n",
        "        hidden_layer_sizes=config[\"hidden_layers\"],\n",
        "        max_iter=300,          # Reduced iterations for speed\n",
        "        batch_size='auto',     # Faster with auto batch sizing\n",
        "        solver='adam',         # Adam optimizer is usually faster\n",
        "        early_stopping=True,   # Stop when validation doesn't improve\n",
        "        n_iter_no_change=10,   # Stop after 10 iterations without improvement\n",
        "        validation_fraction=0.1,\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    exec_time = time.time() - start_time\n",
        "\n",
        "    # Calculate errors\n",
        "    train_error = 1 - model.score(X_train, y_train)\n",
        "    val_error = 1 - model.score(X_val, y_val)\n",
        "\n",
        "    # Print results\n",
        "    print(f\"{data_size:<10} {config['name']:<30} {train_error:.6f}     {val_error:.6f}     {exec_time:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kgud-FUKNnNv",
        "outputId": "4e84e732-f8e5-451f-b401-6f55366d3b3c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data size  Configuration                  Training error  Validation error Time (s)       \n",
            "--------------------------------------------------------------------------------\n",
            "1000       1 hidden layer 4 nodes         0.255000     0.250000     0.07\n",
            "10000      1 hidden layer 4 nodes         0.011125     0.016000     0.84\n",
            "100000     1 hidden layer 4 nodes         0.000500     0.000750     4.34\n",
            "1000       2 hidden layers of 4 nodes each 0.237500     0.220000     0.04\n",
            "10000      2 hidden layers of 4 nodes each 0.007250     0.005500     1.12\n",
            "100000     2 hidden layers of 4 nodes each 0.000812     0.001250     5.16\n"
          ]
        }
      ]
    }
  ]
}